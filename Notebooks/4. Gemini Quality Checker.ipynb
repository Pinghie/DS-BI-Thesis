{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2013cf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a582b982",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_df = pd.read_csv(\"data/manual_annotated_dataset/manual_data.csv\")\n",
    "cleaned_df = pd.read_csv(\"data/cleaned_dataset/merged.tsv\", sep=\",\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40187154",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merged_df = manual_df.merge(cleaned_df, how='left', left_on='id', right_on=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2435f536",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Rimuovo i testi usati nel few shot prompt\n",
    "prompt_text = [\"ParlaMint-IT_2014-03-26-LEG17-Senato-sed-217.u153\", \"ParlaMint-IT_2013-06-25-LEG17-Senato-sed-50.u53\", \"ParlaMint-IT_2018-06-05-LEG18-Senato-sed-9.u62\",\"ParlaMint-IT_2021-06-09-LEG18-Senato-sed-334.u46\"]\n",
    "ground_df = merged_df.drop(merged_df[merged_df['id'].isin(prompt_text)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f864ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estraggo i testi da dare in input a gemini\n",
    "texts_to_classify = []\n",
    "for id in ground_df[\"id\"]:\n",
    "    texts_to_classify.append((id, ground_df[ground_df[\"id\"] == id].text.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caf78b9",
   "metadata": {},
   "source": [
    "### GEN AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39517078",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"\"\n",
    "genai.configure(api_key=API_KEY)\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4aceadb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_record(text_id, text, prompt, model):\n",
    "    filled_prompt = prompt.replace('[$$$]',text)\n",
    "    res = model.generate_content(filled_prompt)\n",
    "    time.sleep(4)\n",
    "    return str(text_id + \",\" +res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1d6d289",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CALCOLO CLASSIFICAZIONI GEMINI\n",
    "def calcola_classificazioni(texts_to_classify, prompt):\n",
    "    i = 0\n",
    "    gemini_classes = []\n",
    "    for tupla in texts_to_classify:\n",
    "        res = classify_record(tupla[0], tupla[1], prompt, model)\n",
    "        gemini_classes.append(res)\n",
    "        i+=1\n",
    "        print(i, end = \" \")\n",
    "        \n",
    "    classification_list = []\n",
    "    for stringa in gemini_classes:\n",
    "        stringa = stringa.strip(\"\\n\")\n",
    "        lista = stringa.split(\",\")\n",
    "        lista = [lista[0]] + [int(x) for x in lista[1:]]\n",
    "        classification_list.append(lista)\n",
    "\n",
    "    classification_df = pd.DataFrame(classification_list, columns = ['id', 'manichean', 'indivisible', 'peoplecentrism', 'antielitism'])\n",
    "    return classification_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c920974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCOLO CLASSIFICAZIONI GEMINI - CON PROB\n",
    "def calcola_classificazioni_prob(texts_to_classify, prompt):\n",
    "    i = 0\n",
    "    gemini_classes = []\n",
    "    for tupla in texts_to_classify:\n",
    "        res = classify_record(tupla[0], tupla[1], prompt, model)\n",
    "        gemini_classes.append(res)\n",
    "        i+=1\n",
    "        print(i, end = \" \")\n",
    "        \n",
    "    classification_list = []\n",
    "    for stringa in gemini_classes:\n",
    "        stringa = stringa.strip(\"\\n\")\n",
    "        lista = stringa.split(\",\")\n",
    "        lista = [lista[0]] + [int(x) for x in lista[1:]]\n",
    "        classification_list.append(lista)\n",
    "\n",
    "    classification_df = pd.DataFrame(classification_list, columns = ['id', 'manichean', 'indivisible', 'peoplecentrism', 'antielitism', 'prob'])\n",
    "    return classification_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aed2a259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcola_prestazioni(ground_df, classification_df):\n",
    "    dimensions = ['manichean', 'indivisible', 'peoplecentrism', 'antielitism']\n",
    "    for dim in dimensions:\n",
    "        print(\"ANALISI: \", dim)\n",
    "        print(\"SPEARMAN: \", stats.spearmanr(ground_df[dim], classification_df[dim]))\n",
    "        print(\"MSE: \", mean_squared_error(ground_df[dim], classification_df[dim]))\n",
    "        print(\"MAE: \", mean_absolute_error(ground_df[dim], classification_df[dim]))\n",
    "        print(classification_report(ground_df[dim], classification_df[dim]))\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8e75e7",
   "metadata": {},
   "source": [
    "### Few Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0c3a3107",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('genai/prompt.txt', 'r', encoding=\"utf8\") as f:\n",
    "    prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "813ed275",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df = pd.read_csv(\"genai/50_texts_classifications.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "#classification_df = calcola_classificazioni(texts_to_classify, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3fee0202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification_df.to_csv(\"genai/50_texts_classifications.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88dbd1a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISI:  manichean\n",
      "SPEARMAN:  SignificanceResult(statistic=0.4798490862098994, pvalue=0.0004215637593474558)\n",
      "MSE:  0.72\n",
      "MAE:  0.68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.62      0.54        16\n",
      "           1       0.38      0.10      0.16        30\n",
      "           2       0.19      1.00      0.32         4\n",
      "\n",
      "    accuracy                           0.34        50\n",
      "   macro avg       0.35      0.58      0.34        50\n",
      "weighted avg       0.39      0.34      0.29        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  indivisible\n",
      "SPEARMAN:  SignificanceResult(statistic=0.34079272776582015, pvalue=0.015443709024348141)\n",
      "MSE:  0.26\n",
      "MAE:  0.22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.88        38\n",
      "           1       0.75      0.27      0.40        11\n",
      "           2       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.52      0.42      0.43        50\n",
      "weighted avg       0.78      0.80      0.76        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  peoplecentrism\n",
      "SPEARMAN:  SignificanceResult(statistic=0.7544924701202814, pvalue=2.4902590055077796e-10)\n",
      "MSE:  0.3\n",
      "MAE:  0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.86      0.69        14\n",
      "           1       0.80      0.50      0.62        24\n",
      "           2       0.79      0.92      0.85        12\n",
      "\n",
      "    accuracy                           0.70        50\n",
      "   macro avg       0.72      0.76      0.72        50\n",
      "weighted avg       0.73      0.70      0.69        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  antielitism\n",
      "SPEARMAN:  SignificanceResult(statistic=0.7803874692985469, pvalue=2.3629355084481826e-11)\n",
      "MSE:  0.34\n",
      "MAE:  0.34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81        19\n",
      "           1       0.50      0.35      0.41        17\n",
      "           2       0.60      0.86      0.71        14\n",
      "\n",
      "    accuracy                           0.66        50\n",
      "   macro avg       0.64      0.67      0.64        50\n",
      "weighted avg       0.65      0.66      0.65        50\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "calcola_prestazioni(ground_df, classification_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cccd000",
   "metadata": {},
   "source": [
    "### Zero Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60fa3972",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('genai/zero-shot-prompt.txt', 'r', encoding=\"utf8\") as f:\n",
    "    zero_shot_prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9628bb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_classification = pd.read_csv(\"genai/zero-shot_50_texts_classifications.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "#zero_shot_classification = calcola_classificazioni(texts_to_classify, zero_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "acdbf688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero_shot_classification.to_csv(\"genai/zero-shot_50_texts_classifications.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71d27062",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISI:  manichean\n",
      "SPEARMAN:  SignificanceResult(statistic=0.47194179129308417, pvalue=0.0005401452787881557)\n",
      "MSE:  0.48\n",
      "MAE:  0.48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.75      0.59        16\n",
      "           1       0.69      0.37      0.48        30\n",
      "           2       0.33      0.75      0.46         4\n",
      "\n",
      "    accuracy                           0.52        50\n",
      "   macro avg       0.50      0.62      0.51        50\n",
      "weighted avg       0.59      0.52      0.51        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  indivisible\n",
      "SPEARMAN:  SignificanceResult(statistic=0.46561492289988066, pvalue=0.0006558392124161011)\n",
      "MSE:  0.2\n",
      "MAE:  0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89        38\n",
      "           1       0.57      0.36      0.44        11\n",
      "           2       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.47      0.44      0.44        50\n",
      "weighted avg       0.76      0.80      0.77        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  peoplecentrism\n",
      "SPEARMAN:  SignificanceResult(statistic=0.6192824648172023, pvalue=1.6306407440315195e-06)\n",
      "MSE:  0.48\n",
      "MAE:  0.44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.43      0.50        14\n",
      "           1       0.60      0.50      0.55        24\n",
      "           2       0.55      0.92      0.69        12\n",
      "\n",
      "    accuracy                           0.58        50\n",
      "   macro avg       0.58      0.62      0.58        50\n",
      "weighted avg       0.59      0.58      0.57        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  antielitism\n",
      "SPEARMAN:  SignificanceResult(statistic=0.6820353364676632, pvalue=4.930571218162299e-08)\n",
      "MSE:  0.42\n",
      "MAE:  0.42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.42      0.57        19\n",
      "           1       0.42      0.65      0.51        17\n",
      "           2       0.67      0.71      0.69        14\n",
      "\n",
      "    accuracy                           0.58        50\n",
      "   macro avg       0.66      0.59      0.59        50\n",
      "weighted avg       0.67      0.58      0.58        50\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "calcola_prestazioni(ground_df, zero_shot_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe005b4b",
   "metadata": {},
   "source": [
    "### Binary transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4603a6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_ground_df = ground_df[['id','manichean', 'indivisible', 'peoplecentrism', 'antielitism']].replace(2, 1)\n",
    "bin_classification_df = classification_df.replace(2, 1)\n",
    "bin_zero_classification_df = zero_shot_classification.replace(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d812733",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISI:  manichean\n",
      "SPEARMAN:  SignificanceResult(statistic=0.28492840823101134, pvalue=0.0449016983729226)\n",
      "MSE:  0.34\n",
      "MAE:  0.34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.62      0.54        16\n",
      "           1       0.79      0.68      0.73        34\n",
      "\n",
      "    accuracy                           0.66        50\n",
      "   macro avg       0.63      0.65      0.64        50\n",
      "weighted avg       0.69      0.66      0.67        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  indivisible\n",
      "SPEARMAN:  SignificanceResult(statistic=0.3521347126246435, pvalue=0.012145513123501699)\n",
      "MSE:  0.2\n",
      "MAE:  0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.88        38\n",
      "           1       0.75      0.25      0.38        12\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.78      0.61      0.63        50\n",
      "weighted avg       0.79      0.80      0.76        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  peoplecentrism\n",
      "SPEARMAN:  SignificanceResult(statistic=0.5523285746074869, pvalue=3.2026383236621726e-05)\n",
      "MSE:  0.22\n",
      "MAE:  0.22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.86      0.69        14\n",
      "           1       0.93      0.75      0.83        36\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.75      0.80      0.76        50\n",
      "weighted avg       0.83      0.78      0.79        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  antielitism\n",
      "SPEARMAN:  SignificanceResult(statistic=0.7004727969157798, pvalue=1.4900542898183972e-08)\n",
      "MSE:  0.14\n",
      "MAE:  0.14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81        19\n",
      "           1       0.88      0.90      0.89        31\n",
      "\n",
      "    accuracy                           0.86        50\n",
      "   macro avg       0.85      0.85      0.85        50\n",
      "weighted avg       0.86      0.86      0.86        50\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calcola_prestazioni(bin_ground_df, bin_classification_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44599c8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISI:  manichean\n",
      "SPEARMAN:  SignificanceResult(statistic=0.34299717028501775, pvalue=0.014748787378676192)\n",
      "MSE:  0.34\n",
      "MAE:  0.34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.75      0.59        16\n",
      "           1       0.84      0.62      0.71        34\n",
      "\n",
      "    accuracy                           0.66        50\n",
      "   macro avg       0.66      0.68      0.65        50\n",
      "weighted avg       0.72      0.66      0.67        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  indivisible\n",
      "SPEARMAN:  SignificanceResult(statistic=0.44806644233734894, pvalue=0.0011022839997438436)\n",
      "MSE:  0.18\n",
      "MAE:  0.18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89        38\n",
      "           1       0.71      0.42      0.53        12\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.78      0.68      0.71        50\n",
      "weighted avg       0.81      0.82      0.80        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  peoplecentrism\n",
      "SPEARMAN:  SignificanceResult(statistic=0.35634832254989923, pvalue=0.0110846322614489)\n",
      "MSE:  0.24\n",
      "MAE:  0.24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.43      0.50        14\n",
      "           1       0.80      0.89      0.84        36\n",
      "\n",
      "    accuracy                           0.76        50\n",
      "   macro avg       0.70      0.66      0.67        50\n",
      "weighted avg       0.74      0.76      0.75        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  antielitism\n",
      "SPEARMAN:  SignificanceResult(statistic=0.4912071184519282, pvalue=0.00029216083303630467)\n",
      "MSE:  0.24\n",
      "MAE:  0.24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.42      0.57        19\n",
      "           1       0.73      0.97      0.83        31\n",
      "\n",
      "    accuracy                           0.76        50\n",
      "   macro avg       0.81      0.69      0.70        50\n",
      "weighted avg       0.79      0.76      0.73        50\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calcola_prestazioni(bin_ground_df, bin_zero_classification_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfb78d0",
   "metadata": {},
   "source": [
    "### Zero-shot 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19d151a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('genai/zero-shot_prompt_2.0.txt', 'r', encoding=\"utf8\") as f:\n",
    "    zero_shot_prompt_2 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5bf7bca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 "
     ]
    }
   ],
   "source": [
    "zero_shot_classification = pd.read_csv(\"genai/zero-shot_50_texts_classifications_2.0.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "#zero_shot_classification_2 = calcola_classificazioni_prob(texts_to_classify, zero_shot_prompt_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "02b7f453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 20)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d6c1aa38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 20)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_df[ground_df[\"prob\"]>7].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "97dfd73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 6)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_classification_2[zero_shot_classification_2[\"prob\"]>8].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ec0e83bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_classification_2.to_csv(\"genai/zero-shot_50_texts_classifications_2.0.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5cad06eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISI:  manichean\n",
      "SPEARMAN:  SignificanceResult(statistic=0.011519450637589478, pvalue=0.9437579588512655)\n",
      "MSE:  0.925\n",
      "MAE:  0.725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.43      0.40        14\n",
      "           1       0.56      0.39      0.46        23\n",
      "           2       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.38        40\n",
      "   macro avg       0.31      0.27      0.29        40\n",
      "weighted avg       0.45      0.38      0.41        40\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  indivisible\n",
      "SPEARMAN:  SignificanceResult(statistic=-0.24069390083941855, pvalue=0.13462654509813718)\n",
      "MSE:  0.625\n",
      "MAE:  0.575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.53      0.59        30\n",
      "           1       0.12      0.22      0.16         9\n",
      "           2       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.45        40\n",
      "   macro avg       0.26      0.25      0.25        40\n",
      "weighted avg       0.53      0.45      0.48        40\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  peoplecentrism\n",
      "SPEARMAN:  SignificanceResult(statistic=0.31217355206624436, pvalue=0.04987085343075549)\n",
      "MSE:  0.7\n",
      "MAE:  0.55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.62      0.50        13\n",
      "           1       0.60      0.47      0.53        19\n",
      "           2       0.67      0.50      0.57         8\n",
      "\n",
      "    accuracy                           0.53        40\n",
      "   macro avg       0.56      0.53      0.53        40\n",
      "weighted avg       0.56      0.53      0.53        40\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  antielitism\n",
      "SPEARMAN:  SignificanceResult(statistic=0.044655939524453375, pvalue=0.7843846552050951)\n",
      "MSE:  1.425\n",
      "MAE:  0.925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.18      0.25        17\n",
      "           1       0.36      0.29      0.32        14\n",
      "           2       0.27      0.67      0.39         9\n",
      "\n",
      "    accuracy                           0.33        40\n",
      "   macro avg       0.35      0.38      0.32        40\n",
      "weighted avg       0.37      0.33      0.31        40\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "calcola_prestazioni(ground_df[ground_df[\"prob\"]>7], zero_shot_classification_2[zero_shot_classification_2[\"prob\"]>7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a37929",
   "metadata": {},
   "source": [
    "### Binary directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9c729cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_ground_df = ground_df[['id','manichean', 'indivisible', 'peoplecentrism', 'antielitism']].replace(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aded7878",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('genai/binary_few_prompt.txt', 'r', encoding=\"utf8\") as f:\n",
    "    binary_few_prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "961f4816",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_few_prompt_classification = pd.read_csv(\"genai/binary_few_classifications.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "#binary_few_prompt_classification = calcola_classificazioni(texts_to_classify, binary_few_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "835ed9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary_few_prompt_classification.to_csv(\"genai/binary_few_classifications.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c03d0377",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISI:  manichean\n",
      "SPEARMAN:  SignificanceResult(statistic=0.4353221193479409, pvalue=0.0015802285746497938)\n",
      "MSE:  0.32\n",
      "MAE:  0.32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.88      0.64        16\n",
      "           1       0.91      0.59      0.71        34\n",
      "\n",
      "    accuracy                           0.68        50\n",
      "   macro avg       0.70      0.73      0.68        50\n",
      "weighted avg       0.78      0.68      0.69        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  indivisible\n",
      "SPEARMAN:  SignificanceResult(statistic=0.44806644233734894, pvalue=0.0011022839997438436)\n",
      "MSE:  0.18\n",
      "MAE:  0.18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89        38\n",
      "           1       0.71      0.42      0.53        12\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.78      0.68      0.71        50\n",
      "weighted avg       0.81      0.82      0.80        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  peoplecentrism\n",
      "SPEARMAN:  SignificanceResult(statistic=0.5345224838248488, pvalue=6.374436754429389e-05)\n",
      "MSE:  0.26\n",
      "MAE:  0.26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.93      0.67        14\n",
      "           1       0.96      0.67      0.79        36\n",
      "\n",
      "    accuracy                           0.74        50\n",
      "   macro avg       0.74      0.80      0.73        50\n",
      "weighted avg       0.84      0.74      0.75        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  antielitism\n",
      "SPEARMAN:  SignificanceResult(statistic=0.7004727969157798, pvalue=1.4900542898183972e-08)\n",
      "MSE:  0.16\n",
      "MAE:  0.16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.95      0.82        19\n",
      "           1       0.96      0.77      0.86        31\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.84      0.86      0.84        50\n",
      "weighted avg       0.87      0.84      0.84        50\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calcola_prestazioni(bin_ground_df, binary_few_prompt_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cdc88c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
