{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "245e2020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a2a54ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_texts_df = pd.read_csv(\"data/annotated_dataset/annotated_texts_repr.csv\", sep=\",\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "111309dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>pop_sum</th>\n",
       "      <th>manichean</th>\n",
       "      <th>peoplecentrism</th>\n",
       "      <th>antielitism</th>\n",
       "      <th>emotional</th>\n",
       "      <th>polarization</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>doc_embedding</th>\n",
       "      <th>doc_embedding_pos</th>\n",
       "      <th>linguistic_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ParlaMint-IT_2013-08-01-LEG17-Senato-sed-86.u153</td>\n",
       "      <td>PETROCELLI . Signor Presidente, senatrici e se...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.5361957907801886, 0.049413195954373046, 0.0...</td>\n",
       "      <td>[0.009776607354980394, 0.04375904489842546, -0...</td>\n",
       "      <td>[0.0025272382080579183, 0.002842237250819832, ...</td>\n",
       "      <td>[47.0, 1831.0, 38.95744680851064, 4.6773997569...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ParlaMint-IT_2014-02-05-LEG17-Senato-sed-184.u79</td>\n",
       "      <td>Lo dico al senatore Casson e agli altri: capis...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.46272910958786384, 0.09530122244710613, -0....</td>\n",
       "      <td>[0.01605109330957291, 0.024485928836790936, -0...</td>\n",
       "      <td>[0.003973030663484822, -0.023834898513667484, ...</td>\n",
       "      <td>[74.0, 1771.0, 23.93243243243243, 5.1573248407...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 id  \\\n",
       "0  ParlaMint-IT_2013-08-01-LEG17-Senato-sed-86.u153   \n",
       "1  ParlaMint-IT_2014-02-05-LEG17-Senato-sed-184.u79   \n",
       "\n",
       "                                                text  pop_sum  manichean  \\\n",
       "0  PETROCELLI . Signor Presidente, senatrici e se...        4          1   \n",
       "1  Lo dico al senatore Casson e agli altri: capis...        3          0   \n",
       "\n",
       "   peoplecentrism  antielitism  emotional  polarization  \\\n",
       "0               1            1          1             1   \n",
       "1               1            1          1             1   \n",
       "\n",
       "                                               tfidf  \\\n",
       "0  [0.5361957907801886, 0.049413195954373046, 0.0...   \n",
       "1  [0.46272910958786384, 0.09530122244710613, -0....   \n",
       "\n",
       "                                       doc_embedding  \\\n",
       "0  [0.009776607354980394, 0.04375904489842546, -0...   \n",
       "1  [0.01605109330957291, 0.024485928836790936, -0...   \n",
       "\n",
       "                                   doc_embedding_pos  \\\n",
       "0  [0.0025272382080579183, 0.002842237250819832, ...   \n",
       "1  [0.003973030663484822, -0.023834898513667484, ...   \n",
       "\n",
       "                                  linguistic_profile  \n",
       "0  [47.0, 1831.0, 38.95744680851064, 4.6773997569...  \n",
       "1  [74.0, 1771.0, 23.93243243243243, 5.1573248407...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_texts_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ccf7c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fit_multiple_models(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    #LightGBM\n",
    "    clf_lgbm = LGBMClassifier(random_state=8)\n",
    "    clf_lgbm.fit(X_train, y_train)\n",
    "    y_pred = clf_lgbm.predict(X_test)\n",
    "    print(\"=======LIGHTGBM: \\n\", classification_report(y_test ,y_pred))\n",
    "\n",
    "    #Linear SVC\n",
    "    clf_linear_svc = LinearSVC(C=1.0, random_state=42)\n",
    "    clf_linear_svc.fit(X_train, y_train)\n",
    "    y_pred = clf_linear_svc.predict(X_test)\n",
    "    print(\"=======LINEAR SVC: \\n\",classification_report(y_test, y_pred))\n",
    "    \n",
    "    #Non-Linear SVC\n",
    "    clf_svc = SVC(gamma='auto', C=0.1, kernel='rbf', random_state=42)\n",
    "    clf_svc.fit(X_train, y_train)\n",
    "    y_pred = clf_svc.predict(X_test)\n",
    "    print(\"=======NON-LINEAR SVC: \\n\",classification_report(y_test, y_pred))\n",
    "    \n",
    "    #Random Forest\n",
    "    clf_rf = RandomForestClassifier(n_estimators=150, \n",
    "                             criterion='gini', \n",
    "                             max_depth=None, \n",
    "                             min_samples_split=2, \n",
    "                             min_samples_leaf=1, \n",
    "                             min_weight_fraction_leaf=0.0, \n",
    "                             max_features='sqrt', \n",
    "                             random_state=0, \n",
    "                             n_jobs=-1)\n",
    "    clf_rf.fit(X_train, y_train)\n",
    "    y_pred = clf_rf.predict(X_test)\n",
    "    print(\"========RANDOM FOREST: \\n\", classification_report(y_test, y_pred))\n",
    "    '''\n",
    "    #Bagging\n",
    "    clf_bag = BaggingClassifier(estimator=None, n_estimators=100, random_state=0)\n",
    "    clf_bag.fit(X_train, y_train)\n",
    "    y_pred = clf_bag.predict(X_test)\n",
    "    print(\"========BAGGING: \\n\", classification_report(y_test, y_pred))\n",
    "    \n",
    "    #Bagging SVC\n",
    "    clf_bag_svc = BaggingClassifier(estimator=SVC(C=1000), n_estimators=10, random_state=0)\n",
    "    clf_bag_svc.fit(X_train, y_train)\n",
    "    y_pred = clf_bag_svc.predict(X_test)\n",
    "    print(\"========BAGGING SVC: \\n\", classification_report(y_test, y_pred))\n",
    "    \n",
    "    #Bagging RF\n",
    "    clf_bag_rf = BaggingClassifier(estimator=RandomForestClassifier(n_estimators=100), n_estimators=100, random_state=0)\n",
    "    clf_bag_rf.fit(X_train, y_train)\n",
    "    y_pred = clf_bag_rf.predict(X_test)\n",
    "    print(\"========BAGGING RF: \\n\", classification_report(y_test, y_pred))\n",
    "    '''\n",
    "    #AdaBoost\n",
    "    clf_ada = AdaBoostClassifier(estimator=None, n_estimators=100, random_state=0)\n",
    "    clf_ada.fit(X_train, y_train)\n",
    "    y_pred = clf_ada.predict(X_test)\n",
    "    print(\"========ADABOOST \\n\", classification_report(y_test, y_pred))\n",
    "    \n",
    "    #AdaBoost RF\n",
    "    clf_ada_rf = AdaBoostClassifier(estimator=RandomForestClassifier(n_estimators=100), n_estimators=100, random_state=0)\n",
    "    clf_ada_rf.fit(X_train, y_train)\n",
    "    y_pred = clf_ada_rf.predict(X_test)\n",
    "    print(\"========ADABOOST RF \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "906129c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fit_best_params(X_train, X_test, y_train, y_test):\n",
    "    #Light GBM\n",
    "    param_dist = {\n",
    "        'n_estimators': randint(100, 1200),                # Range for boosting rounds\n",
    "        'learning_rate': uniform(0.001, 0.3),              # Learning rate\n",
    "        'num_leaves': randint(20, 150),                    # Maximum number of leaves in one tree\n",
    "        'max_depth': randint(3, 15),                       # Maximum depth of the tree\n",
    "        'min_data_in_leaf': randint(10, 100),              # Minimum number of samples in a leaf\n",
    "        'feature_fraction': uniform(0.5, 0.5),             # Proportion of features to consider at each split\n",
    "        'bagging_fraction': uniform(0.5, 0.5),             # Proportion of data to consider at each iteration\n",
    "        'bagging_freq': randint(1, 10),                    # Frequency of bagging\n",
    "        'lambda_l1': uniform(0, 5),                        # L1 regularization term\n",
    "        'lambda_l2': uniform(0, 5)                         # L2 regularization term\n",
    "    }\n",
    "\n",
    "    clf_lgb = lgb.LGBMClassifier(verbose=-1, random_state=42)\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=clf_lgb,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=50,                   # Number of parameter settings sampled\n",
    "        scoring='accuracy',\n",
    "        cv=5,\n",
    "        verbose=2,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    random_search.fit(X_train, y_train)\n",
    "    selected_clf =  random_search.best_estimator_\n",
    "    selected_clf.fit(X_train, y_train)\n",
    "    y_pred = selected_clf.predict(X_test)\n",
    "    print(\"=======BEST PARAM LIGHTGBM:\\n\", classification_report(y_test ,y_pred))\n",
    "    \n",
    "    #Random Forest\n",
    "    param_dist = {\n",
    "        'n_estimators': randint(100, 500),                  # Number of trees\n",
    "        'max_depth': randint(5, 15),                         # Maximum depth of each tree\n",
    "        'min_samples_split': randint(2, 20),                 # Minimum samples needed to split a node\n",
    "        'min_samples_leaf': randint(1, 20),                  # Minimum samples needed in each leaf\n",
    "        'max_features': ['sqrt', 'log2', None],              # Number of features to consider at each split\n",
    "        'bootstrap': [True, False],                          # Whether to use bootstrapping\n",
    "        'class_weight': [None, 'balanced']                   # Handle class imbalance\n",
    "    }\n",
    "\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=clf,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=20,                   \n",
    "        scoring='accuracy',          \n",
    "        cv=5,\n",
    "        verbose=2,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    random_search.fit(X_train, y_train)\n",
    "    selected_clf =  random_search.best_estimator_\n",
    "    selected_clf.fit(X_train, y_train)\n",
    "    y_pred = selected_clf.predict(X_test)\n",
    "    print(\"=======BEST PARAM RANDOM FOREST:\\n\", classification_report(y_test ,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1cfc53",
   "metadata": {},
   "source": [
    "### Populism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21775c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop_train, df_pop_test = train_test_split(annotated_texts_df, test_size=0.25, stratify=annotated_texts_df['pop_sum'], random_state=42)\n",
    "y_train_pop = df_pop_train[\"pop_sum\"].values\n",
    "y_test_pop = df_pop_test[\"pop_sum\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4751ce5d",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dae2da21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 76500\n",
      "[LightGBM] [Info] Number of data points in the train set: 8130, number of used features: 300\n",
      "[LightGBM] [Info] Start training from score -0.998283\n",
      "[LightGBM] [Info] Start training from score -1.520072\n",
      "[LightGBM] [Info] Start training from score -2.189872\n",
      "[LightGBM] [Info] Start training from score -2.392620\n",
      "[LightGBM] [Info] Start training from score -1.563170\n",
      "=======LIGHTGBM: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.85      0.73       999\n",
      "           1       0.42      0.41      0.41       593\n",
      "           2       0.21      0.05      0.08       303\n",
      "           3       0.29      0.05      0.08       248\n",
      "           4       0.63      0.76      0.69       567\n",
      "\n",
      "    accuracy                           0.57      2710\n",
      "   macro avg       0.44      0.42      0.40      2710\n",
      "weighted avg       0.51      0.57      0.52      2710\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======LINEAR SVC: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.89      0.76       999\n",
      "           1       0.49      0.44      0.46       593\n",
      "           2       0.23      0.02      0.04       303\n",
      "           3       0.29      0.02      0.04       248\n",
      "           4       0.61      0.86      0.71       567\n",
      "\n",
      "    accuracy                           0.61      2710\n",
      "   macro avg       0.46      0.45      0.40      2710\n",
      "weighted avg       0.53      0.61      0.54      2710\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======NON-LINEAR SVC: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      1.00      0.54       999\n",
      "           1       0.00      0.00      0.00       593\n",
      "           2       0.00      0.00      0.00       303\n",
      "           3       0.00      0.00      0.00       248\n",
      "           4       0.00      0.00      0.00       567\n",
      "\n",
      "    accuracy                           0.37      2710\n",
      "   macro avg       0.07      0.20      0.11      2710\n",
      "weighted avg       0.14      0.37      0.20      2710\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========RANDOM FOREST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.94      0.66       999\n",
      "           1       0.42      0.20      0.28       593\n",
      "           2       0.50      0.00      0.01       303\n",
      "           3       0.00      0.00      0.00       248\n",
      "           4       0.66      0.65      0.66       567\n",
      "\n",
      "    accuracy                           0.53      2710\n",
      "   macro avg       0.42      0.36      0.32      2710\n",
      "weighted avg       0.47      0.53      0.44      2710\n",
      "\n",
      "========ADABOOST \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.77      0.71       999\n",
      "           1       0.41      0.42      0.41       593\n",
      "           2       0.17      0.08      0.11       303\n",
      "           3       0.19      0.09      0.12       248\n",
      "           4       0.59      0.70      0.64       567\n",
      "\n",
      "    accuracy                           0.54      2710\n",
      "   macro avg       0.40      0.41      0.40      2710\n",
      "weighted avg       0.49      0.54      0.51      2710\n",
      "\n",
      "========ADABOOST RF \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.93      0.66       999\n",
      "           1       0.40      0.22      0.28       593\n",
      "           2       0.50      0.01      0.02       303\n",
      "           3       0.50      0.00      0.01       248\n",
      "           4       0.63      0.62      0.63       567\n",
      "\n",
      "    accuracy                           0.52      2710\n",
      "   macro avg       0.51      0.36      0.32      2710\n",
      "weighted avg       0.51      0.52      0.44      2710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = df_pop_train[\"tfidf\"].values\n",
    "X_test = df_pop_test[\"tfidf\"].values\n",
    "\n",
    "X_train = np.array([ast.literal_eval(item) for item in X_train])\n",
    "X_test = np.array([ast.literal_eval(item) for item in X_test])\n",
    "\n",
    "train_fit_multiple_models(X_train, X_test, y_train_pop, y_test_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12c0c85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_fit_best_params(X_train, X_test, y_train_pop, y_test_pop)\n",
      "Cell \u001b[1;32mIn[5], line 29\u001b[0m, in \u001b[0;36mtrain_fit_best_params\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m     16\u001b[0m clf_lgb \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMClassifier(verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     18\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m     19\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mclf_lgb,\n\u001b[0;32m     20\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_dist,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     27\u001b[0m )\n\u001b[1;32m---> 29\u001b[0m random_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     30\u001b[0m selected_clf \u001b[38;5;241m=\u001b[39m  random_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     31\u001b[0m selected_clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1806\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1805\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1806\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1807\u001b[0m         ParameterSampler(\n\u001b[0;32m   1808\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_distributions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[0;32m   1809\u001b[0m         )\n\u001b[0;32m   1810\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_fit_best_params(X_train, X_test, y_train_pop, y_test_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83450d9",
   "metadata": {},
   "source": [
    "#### Doc Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c9eab21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32640\n",
      "[LightGBM] [Info] Number of data points in the train set: 8130, number of used features: 128\n",
      "[LightGBM] [Info] Start training from score -0.998283\n",
      "[LightGBM] [Info] Start training from score -1.520072\n",
      "[LightGBM] [Info] Start training from score -2.189872\n",
      "[LightGBM] [Info] Start training from score -2.392620\n",
      "[LightGBM] [Info] Start training from score -1.563170\n",
      "=======LIGHTGBM: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.83      0.73       999\n",
      "           1       0.40      0.39      0.39       593\n",
      "           2       0.22      0.07      0.10       303\n",
      "           3       0.26      0.06      0.10       248\n",
      "           4       0.58      0.74      0.65       567\n",
      "\n",
      "    accuracy                           0.56      2710\n",
      "   macro avg       0.42      0.42      0.40      2710\n",
      "weighted avg       0.50      0.56      0.51      2710\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======LINEAR SVC: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.90      0.71       999\n",
      "           1       0.49      0.26      0.34       593\n",
      "           2       0.00      0.00      0.00       303\n",
      "           3       0.00      0.00      0.00       248\n",
      "           4       0.53      0.79      0.63       567\n",
      "\n",
      "    accuracy                           0.56      2710\n",
      "   macro avg       0.32      0.39      0.34      2710\n",
      "weighted avg       0.43      0.56      0.47      2710\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======NON-LINEAR SVC: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      1.00      0.54       999\n",
      "           1       0.00      0.00      0.00       593\n",
      "           2       0.00      0.00      0.00       303\n",
      "           3       0.00      0.00      0.00       248\n",
      "           4       0.00      0.00      0.00       567\n",
      "\n",
      "    accuracy                           0.37      2710\n",
      "   macro avg       0.07      0.20      0.11      2710\n",
      "weighted avg       0.14      0.37      0.20      2710\n",
      "\n",
      "========RANDOM FOREST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.85      0.72       999\n",
      "           1       0.41      0.38      0.39       593\n",
      "           2       0.18      0.01      0.02       303\n",
      "           3       0.50      0.02      0.04       248\n",
      "           4       0.55      0.75      0.64       567\n",
      "\n",
      "    accuracy                           0.56      2710\n",
      "   macro avg       0.45      0.40      0.36      2710\n",
      "weighted avg       0.50      0.56      0.49      2710\n",
      "\n",
      "========ADABOOST \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.78      0.71       999\n",
      "           1       0.40      0.40      0.40       593\n",
      "           2       0.21      0.04      0.06       303\n",
      "           3       0.21      0.07      0.10       248\n",
      "           4       0.54      0.74      0.62       567\n",
      "\n",
      "    accuracy                           0.54      2710\n",
      "   macro avg       0.40      0.41      0.38      2710\n",
      "weighted avg       0.48      0.54      0.50      2710\n",
      "\n",
      "========ADABOOST RF \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.86      0.72       999\n",
      "           1       0.42      0.37      0.39       593\n",
      "           2       0.21      0.02      0.04       303\n",
      "           3       0.00      0.00      0.00       248\n",
      "           4       0.55      0.74      0.63       567\n",
      "\n",
      "    accuracy                           0.55      2710\n",
      "   macro avg       0.36      0.40      0.36      2710\n",
      "weighted avg       0.46      0.55      0.49      2710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = df_pop_train[\"doc_embedding\"].values\n",
    "X_test = df_pop_test[\"doc_embedding\"].values\n",
    "\n",
    "X_train = np.array([ast.literal_eval(item) for item in X_train])\n",
    "X_test = np.array([ast.literal_eval(item) for item in X_test])\n",
    "\n",
    "train_fit_multiple_models(X_train, X_test, y_train_pop, y_test_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f449a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fit_best_params(X_train, X_test, y_train_pop, y_test_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff851b3",
   "metadata": {},
   "source": [
    "#### Doc Embedding POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9409d24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32640\n",
      "[LightGBM] [Info] Number of data points in the train set: 8130, number of used features: 128\n",
      "[LightGBM] [Info] Start training from score -0.998283\n",
      "[LightGBM] [Info] Start training from score -1.520072\n",
      "[LightGBM] [Info] Start training from score -2.189872\n",
      "[LightGBM] [Info] Start training from score -2.392620\n",
      "[LightGBM] [Info] Start training from score -1.563170\n",
      "=======LIGHTGBM: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.82      0.73       999\n",
      "           1       0.43      0.41      0.42       593\n",
      "           2       0.25      0.08      0.12       303\n",
      "           3       0.24      0.07      0.11       248\n",
      "           4       0.57      0.74      0.65       567\n",
      "\n",
      "    accuracy                           0.56      2710\n",
      "   macro avg       0.43      0.42      0.41      2710\n",
      "weighted avg       0.51      0.56      0.52      2710\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======LINEAR SVC: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.89      0.71       999\n",
      "           1       0.49      0.30      0.37       593\n",
      "           2       0.00      0.00      0.00       303\n",
      "           3       0.00      0.00      0.00       248\n",
      "           4       0.52      0.80      0.63       567\n",
      "\n",
      "    accuracy                           0.56      2710\n",
      "   macro avg       0.32      0.40      0.34      2710\n",
      "weighted avg       0.44      0.56      0.48      2710\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======NON-LINEAR SVC: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      1.00      0.54       999\n",
      "           1       0.00      0.00      0.00       593\n",
      "           2       0.00      0.00      0.00       303\n",
      "           3       0.00      0.00      0.00       248\n",
      "           4       0.00      0.00      0.00       567\n",
      "\n",
      "    accuracy                           0.37      2710\n",
      "   macro avg       0.07      0.20      0.11      2710\n",
      "weighted avg       0.14      0.37      0.20      2710\n",
      "\n",
      "========RANDOM FOREST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.84      0.71       999\n",
      "           1       0.44      0.39      0.41       593\n",
      "           2       0.34      0.03      0.06       303\n",
      "           3       0.57      0.02      0.03       248\n",
      "           4       0.55      0.76      0.64       567\n",
      "\n",
      "    accuracy                           0.56      2710\n",
      "   macro avg       0.50      0.41      0.37      2710\n",
      "weighted avg       0.53      0.56      0.49      2710\n",
      "\n",
      "========ADABOOST \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.77      0.70       999\n",
      "           1       0.39      0.40      0.40       593\n",
      "           2       0.20      0.04      0.06       303\n",
      "           3       0.21      0.06      0.09       248\n",
      "           4       0.54      0.72      0.62       567\n",
      "\n",
      "    accuracy                           0.53      2710\n",
      "   macro avg       0.39      0.40      0.37      2710\n",
      "weighted avg       0.47      0.53      0.49      2710\n",
      "\n",
      "========ADABOOST RF \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       999\n",
      "           1       0.44      0.39      0.41       593\n",
      "           2       0.14      0.01      0.02       303\n",
      "           3       0.45      0.02      0.04       248\n",
      "           4       0.55      0.75      0.64       567\n",
      "\n",
      "    accuracy                           0.56      2710\n",
      "   macro avg       0.44      0.40      0.36      2710\n",
      "weighted avg       0.50      0.56      0.49      2710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = df_pop_train[\"doc_embedding_pos\"].values\n",
    "X_test = df_pop_test[\"doc_embedding_pos\"].values\n",
    "\n",
    "X_train = np.array([ast.literal_eval(item) for item in X_train])\n",
    "X_test = np.array([ast.literal_eval(item) for item in X_test])\n",
    "\n",
    "train_fit_multiple_models(X_train, X_test, y_train_pop, y_test_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42508b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fit_best_params(X_train, X_test, y_train_pop, y_test_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0396e74f",
   "metadata": {},
   "source": [
    "#### Linguistic Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0481d36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 33046\n",
      "[LightGBM] [Info] Number of data points in the train set: 8130, number of used features: 140\n",
      "[LightGBM] [Info] Start training from score -0.998283\n",
      "[LightGBM] [Info] Start training from score -1.520072\n",
      "[LightGBM] [Info] Start training from score -2.189872\n",
      "[LightGBM] [Info] Start training from score -2.392620\n",
      "[LightGBM] [Info] Start training from score -1.563170\n",
      "=======LIGHTGBM: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.79      0.67       999\n",
      "           1       0.33      0.33      0.33       593\n",
      "           2       0.09      0.01      0.02       303\n",
      "           3       0.12      0.02      0.03       248\n",
      "           4       0.55      0.67      0.61       567\n",
      "\n",
      "    accuracy                           0.51      2710\n",
      "   macro avg       0.34      0.37      0.33      2710\n",
      "weighted avg       0.42      0.51      0.45      2710\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======LINEAR SVC: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.99      0.58       999\n",
      "           1       0.50      0.01      0.01       593\n",
      "           2       0.00      0.00      0.00       303\n",
      "           3       0.00      0.00      0.00       248\n",
      "           4       0.69      0.37      0.48       567\n",
      "\n",
      "    accuracy                           0.44      2710\n",
      "   macro avg       0.32      0.27      0.21      2710\n",
      "weighted avg       0.41      0.44      0.32      2710\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======NON-LINEAR SVC: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      1.00      0.54       999\n",
      "           1       0.00      0.00      0.00       593\n",
      "           2       0.00      0.00      0.00       303\n",
      "           3       0.00      0.00      0.00       248\n",
      "           4       0.00      0.00      0.00       567\n",
      "\n",
      "    accuracy                           0.37      2710\n",
      "   macro avg       0.07      0.20      0.11      2710\n",
      "weighted avg       0.14      0.37      0.20      2710\n",
      "\n",
      "========RANDOM FOREST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.85      0.66       999\n",
      "           1       0.35      0.25      0.29       593\n",
      "           2       0.00      0.00      0.00       303\n",
      "           3       0.33      0.00      0.01       248\n",
      "           4       0.53      0.67      0.59       567\n",
      "\n",
      "    accuracy                           0.51      2710\n",
      "   macro avg       0.35      0.35      0.31      2710\n",
      "weighted avg       0.42      0.51      0.43      2710\n",
      "\n",
      "========ADABOOST \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.75      0.65       999\n",
      "           1       0.34      0.31      0.33       593\n",
      "           2       0.13      0.02      0.03       303\n",
      "           3       0.13      0.05      0.07       248\n",
      "           4       0.51      0.65      0.57       567\n",
      "\n",
      "    accuracy                           0.49      2710\n",
      "   macro avg       0.34      0.36      0.33      2710\n",
      "weighted avg       0.42      0.49      0.44      2710\n",
      "\n",
      "========ADABOOST RF \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.85      0.66       999\n",
      "           1       0.36      0.25      0.30       593\n",
      "           2       0.33      0.01      0.01       303\n",
      "           3       0.67      0.01      0.02       248\n",
      "           4       0.54      0.68      0.60       567\n",
      "\n",
      "    accuracy                           0.51      2710\n",
      "   macro avg       0.49      0.36      0.32      2710\n",
      "weighted avg       0.49      0.51      0.44      2710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = df_pop_train[\"linguistic_profile\"].values\n",
    "X_test = df_pop_test[\"linguistic_profile\"].values\n",
    "\n",
    "X_train = np.array([ast.literal_eval(item) for item in X_train])\n",
    "X_test = np.array([ast.literal_eval(item) for item in X_test])\n",
    "\n",
    "train_fit_multiple_models(X_train, X_test, y_train_pop, y_test_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2696ca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fit_best_params(X_train, X_test, y_train_pop, y_test_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d730257",
   "metadata": {},
   "source": [
    "## Polarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c4ea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pol_train, df_pol_test = train_test_split(annotated_texts_df, test_size=0.25, stratify=annotated_texts_df['polarization'], random_state=42)\n",
    "\n",
    "y_train_pol = df_pol_train[\"polarization\"].values\n",
    "y_test_pol = df_pol_test[\"polarization\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f53ab7",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0808e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = df_pol_train[\"tfidf\"].values\n",
    "X_test = df_pol_test[\"tfidf\"].values\n",
    "\n",
    "X_train = np.array([ast.literal_eval(item) for item in X_train])\n",
    "X_test = np.array([ast.literal_eval(item) for item in X_test])\n",
    "\n",
    "train_fit_multiple_models(X_train, X_test, y_train_pol, y_test_pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1caed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fit_best_params(X_train, X_test, y_train_pol, y_test_pol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fc34a9",
   "metadata": {},
   "source": [
    "#### Doc Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54ec423e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004972 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32640\n",
      "[LightGBM] [Info] Number of data points in the train set: 8130, number of used features: 128\n",
      "[LightGBM] [Info] Start training from score -1.882064\n",
      "[LightGBM] [Info] Start training from score -0.782375\n",
      "[LightGBM] [Info] Start training from score -0.940568\n",
      "=======LIGHTGBM: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.25      0.34       413\n",
      "           1       0.64      0.73      0.68      1239\n",
      "           2       0.67      0.69      0.68      1058\n",
      "\n",
      "    accuracy                           0.64      2710\n",
      "   macro avg       0.61      0.56      0.57      2710\n",
      "weighted avg       0.63      0.64      0.63      2710\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======LINEAR SVC: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.07      0.12       413\n",
      "           1       0.61      0.70      0.65      1239\n",
      "           2       0.60      0.70      0.64      1058\n",
      "\n",
      "    accuracy                           0.60      2710\n",
      "   macro avg       0.60      0.49      0.47      2710\n",
      "weighted avg       0.60      0.60      0.57      2710\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======NON-LINEAR SVC: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       413\n",
      "           1       0.46      1.00      0.63      1239\n",
      "           2       0.00      0.00      0.00      1058\n",
      "\n",
      "    accuracy                           0.46      2710\n",
      "   macro avg       0.15      0.33      0.21      2710\n",
      "weighted avg       0.21      0.46      0.29      2710\n",
      "\n",
      "========RANDOM FOREST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.17      0.27       413\n",
      "           1       0.63      0.75      0.68      1239\n",
      "           2       0.65      0.68      0.67      1058\n",
      "\n",
      "    accuracy                           0.64      2710\n",
      "   macro avg       0.62      0.54      0.54      2710\n",
      "weighted avg       0.63      0.64      0.61      2710\n",
      "\n",
      "========ADABOOST \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.30      0.36       413\n",
      "           1       0.60      0.66      0.63      1239\n",
      "           2       0.62      0.64      0.63      1058\n",
      "\n",
      "    accuracy                           0.60      2710\n",
      "   macro avg       0.56      0.53      0.54      2710\n",
      "weighted avg       0.59      0.60      0.59      2710\n",
      "\n",
      "========ADABOOST RF \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.15      0.23       413\n",
      "           1       0.62      0.74      0.68      1239\n",
      "           2       0.65      0.68      0.67      1058\n",
      "\n",
      "    accuracy                           0.63      2710\n",
      "   macro avg       0.60      0.53      0.53      2710\n",
      "weighted avg       0.62      0.63      0.61      2710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = df_pol_train[\"doc_embedding\"].values\n",
    "X_test = df_pol_test[\"doc_embedding\"].values\n",
    "\n",
    "X_train = np.array([ast.literal_eval(item) for item in X_train])\n",
    "X_test = np.array([ast.literal_eval(item) for item in X_test])\n",
    "\n",
    "train_fit_multiple_models(X_train, X_test, y_train_pol, y_test_pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a819158",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fit_best_params(X_train, X_test, y_train_pol, y_test_pol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb099033",
   "metadata": {},
   "source": [
    "#### POS Doc Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "257cebba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32640\n",
      "[LightGBM] [Info] Number of data points in the train set: 8130, number of used features: 128\n",
      "[LightGBM] [Info] Start training from score -1.882064\n",
      "[LightGBM] [Info] Start training from score -0.782375\n",
      "[LightGBM] [Info] Start training from score -0.940568\n",
      "=======LIGHTGBM: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.26      0.35       413\n",
      "           1       0.64      0.73      0.68      1239\n",
      "           2       0.66      0.68      0.67      1058\n",
      "\n",
      "    accuracy                           0.64      2710\n",
      "   macro avg       0.61      0.56      0.57      2710\n",
      "weighted avg       0.63      0.64      0.63      2710\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======LINEAR SVC: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.11      0.18       413\n",
      "           1       0.61      0.72      0.66      1239\n",
      "           2       0.62      0.68      0.65      1058\n",
      "\n",
      "    accuracy                           0.61      2710\n",
      "   macro avg       0.58      0.50      0.50      2710\n",
      "weighted avg       0.60      0.61      0.58      2710\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======NON-LINEAR SVC: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       413\n",
      "           1       0.46      1.00      0.63      1239\n",
      "           2       0.00      0.00      0.00      1058\n",
      "\n",
      "    accuracy                           0.46      2710\n",
      "   macro avg       0.15      0.33      0.21      2710\n",
      "weighted avg       0.21      0.46      0.29      2710\n",
      "\n",
      "========RANDOM FOREST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.16      0.24       413\n",
      "           1       0.62      0.73      0.67      1239\n",
      "           2       0.63      0.66      0.65      1058\n",
      "\n",
      "    accuracy                           0.62      2710\n",
      "   macro avg       0.59      0.52      0.52      2710\n",
      "weighted avg       0.61      0.62      0.59      2710\n",
      "\n",
      "========ADABOOST \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.31      0.38       413\n",
      "           1       0.60      0.65      0.63      1239\n",
      "           2       0.60      0.63      0.62      1058\n",
      "\n",
      "    accuracy                           0.59      2710\n",
      "   macro avg       0.56      0.53      0.54      2710\n",
      "weighted avg       0.58      0.59      0.59      2710\n",
      "\n",
      "========ADABOOST RF \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.16      0.24       413\n",
      "           1       0.62      0.74      0.68      1239\n",
      "           2       0.64      0.68      0.66      1058\n",
      "\n",
      "    accuracy                           0.63      2710\n",
      "   macro avg       0.60      0.53      0.53      2710\n",
      "weighted avg       0.62      0.63      0.60      2710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = df_pol_train[\"doc_embedding_pos\"].values\n",
    "X_test = df_pol_test[\"doc_embedding_pos\"].values\n",
    "\n",
    "X_train = np.array([ast.literal_eval(item) for item in X_train])\n",
    "X_test = np.array([ast.literal_eval(item) for item in X_test])\n",
    "\n",
    "train_fit_multiple_models(X_train, X_test, y_train_pol, y_test_pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ccb605",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fit_best_params(X_train, X_test, y_train_pol, y_test_pol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f92cf26",
   "metadata": {},
   "source": [
    "#### Linguistic Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74ce8e05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 33056\n",
      "[LightGBM] [Info] Number of data points in the train set: 8130, number of used features: 140\n",
      "[LightGBM] [Info] Start training from score -1.882064\n",
      "[LightGBM] [Info] Start training from score -0.782375\n",
      "[LightGBM] [Info] Start training from score -0.940568\n",
      "=======LIGHTGBM: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.13      0.21       413\n",
      "           1       0.60      0.70      0.65      1239\n",
      "           2       0.61      0.66      0.63      1058\n",
      "\n",
      "    accuracy                           0.60      2710\n",
      "   macro avg       0.56      0.50      0.49      2710\n",
      "weighted avg       0.58      0.60      0.57      2710\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======LINEAR SVC: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.00      0.00       413\n",
      "           1       0.46      1.00      0.63      1239\n",
      "           2       0.73      0.01      0.02      1058\n",
      "\n",
      "    accuracy                           0.46      2710\n",
      "   macro avg       0.56      0.34      0.22      2710\n",
      "weighted avg       0.57      0.46      0.30      2710\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======NON-LINEAR SVC: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       413\n",
      "           1       0.46      1.00      0.63      1239\n",
      "           2       0.00      0.00      0.00      1058\n",
      "\n",
      "    accuracy                           0.46      2710\n",
      "   macro avg       0.15      0.33      0.21      2710\n",
      "weighted avg       0.21      0.46      0.29      2710\n",
      "\n",
      "========RANDOM FOREST: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.02      0.04       413\n",
      "           1       0.58      0.73      0.65      1239\n",
      "           2       0.60      0.65      0.62      1058\n",
      "\n",
      "    accuracy                           0.59      2710\n",
      "   macro avg       0.60      0.46      0.43      2710\n",
      "weighted avg       0.59      0.59      0.54      2710\n",
      "\n",
      "========ADABOOST \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.19      0.25       413\n",
      "           1       0.59      0.63      0.61      1239\n",
      "           2       0.58      0.63      0.60      1058\n",
      "\n",
      "    accuracy                           0.56      2710\n",
      "   macro avg       0.50      0.49      0.49      2710\n",
      "weighted avg       0.55      0.56      0.55      2710\n",
      "\n",
      "========ADABOOST RF \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.02      0.05       413\n",
      "           1       0.58      0.72      0.64      1239\n",
      "           2       0.59      0.64      0.62      1058\n",
      "\n",
      "    accuracy                           0.58      2710\n",
      "   macro avg       0.54      0.46      0.43      2710\n",
      "weighted avg       0.56      0.58      0.54      2710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = df_pol_train[\"linguistic_profile\"].values\n",
    "X_test = df_pol_test[\"linguistic_profile\"].values\n",
    "\n",
    "X_train = np.array([ast.literal_eval(item) for item in X_train])\n",
    "X_test = np.array([ast.literal_eval(item) for item in X_test])\n",
    "\n",
    "train_fit_multiple_models(X_train, X_test, y_train_pol, y_test_pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccf7076",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fit_best_params(X_train, X_test, y_train_pol, y_test_pol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
