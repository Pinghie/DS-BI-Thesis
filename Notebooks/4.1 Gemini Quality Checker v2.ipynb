{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2013cf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a582b982",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_df = pd.read_csv(\"data/manual_annotated_dataset/manual_data_v2.csv\")\n",
    "cleaned_df = pd.read_csv(\"data/cleaned_dataset/merged.tsv\", sep=\",\", encoding=\"utf-8\")\n",
    "\n",
    "merged_df = manual_df.merge(cleaned_df, how='left', left_on='id', right_on=\"ID\")\n",
    "\n",
    "#Rimuovo i testi usati nel few shot prompt\n",
    "prompt_text = [\"ParlaMint-IT_2014-03-26-LEG17-Senato-sed-217.u153\", \"ParlaMint-IT_2013-06-25-LEG17-Senato-sed-50.u53\", \"ParlaMint-IT_2018-06-05-LEG18-Senato-sed-9.u62\",\"ParlaMint-IT_2021-06-09-LEG18-Senato-sed-334.u46\"]\n",
    "ground_df = merged_df.drop(merged_df[merged_df['id'].isin(prompt_text)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f864ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estraggo i testi da dare in input a gemini\n",
    "texts_to_classify = []\n",
    "for id in ground_df[\"id\"]:\n",
    "    texts_to_classify.append((id, ground_df[ground_df[\"id\"] == id].text.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caf78b9",
   "metadata": {},
   "source": [
    "### GEN AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39517078",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"\"\n",
    "genai.configure(api_key=API_KEY)\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4aceadb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_record(text_id, text, prompt, model):\n",
    "    filled_prompt = prompt.replace('[$$$]',text)\n",
    "    res = model.generate_content(filled_prompt)\n",
    "    time.sleep(4)\n",
    "    return str(text_id + \",\" +res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1d6d289",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CALCOLO CLASSIFICAZIONI GEMINI\n",
    "def calcola_classificazioni(texts_to_classify, prompt):\n",
    "    i = 0\n",
    "    gemini_classes = []\n",
    "    for tupla in texts_to_classify:\n",
    "        res = classify_record(tupla[0], tupla[1], prompt, model)\n",
    "        gemini_classes.append(res)\n",
    "        i+=1\n",
    "        print(i, end = \" \")\n",
    "        \n",
    "    classification_list = []\n",
    "    for stringa in gemini_classes:\n",
    "        stringa = stringa.strip(\"\\n\")\n",
    "        lista = stringa.split(\",\")\n",
    "        lista = [lista[0]] + [int(x) for x in lista[1:]]\n",
    "        classification_list.append(lista)\n",
    "\n",
    "    classification_df = pd.DataFrame(classification_list, columns = ['id', 'manichean', 'indivisible', 'peoplecentrism', 'antielitism', 'simplicism', 'emotional'])\n",
    "    return classification_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aed2a259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcola_prestazioni(ground_df, classification_df):\n",
    "    dimensions = ['manichean', 'indivisible', 'peoplecentrism', 'antielitism', 'simplicism', 'emotional']\n",
    "    for dim in dimensions:\n",
    "        print(\"ANALISI: \", dim)\n",
    "        print(\"SPEARMAN: \", stats.spearmanr(ground_df[dim], classification_df[dim]))\n",
    "        print(\"MSE: \", mean_squared_error(ground_df[dim], classification_df[dim]))\n",
    "        print(\"MAE: \", mean_absolute_error(ground_df[dim], classification_df[dim]))\n",
    "        print(classification_report(ground_df[dim], classification_df[dim]))\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8e75e7",
   "metadata": {},
   "source": [
    "### Few Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c3a3107",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('genai/v2/fewshot_6features_prompt.txt', 'r', encoding=\"utf8\") as f:\n",
    "    prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "813ed275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 "
     ]
    }
   ],
   "source": [
    "classification_df = pd.read_csv(\"genai/v2/fewshot_6features_classifications.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "#classification_df = calcola_classificazioni(texts_to_classify, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3fee0202",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df.to_csv(\"genai/v2/fewshot_6features_classifications.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "88dbd1a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISI:  manichean\n",
      "SPEARMAN:  SignificanceResult(statistic=0.8002008986387475, pvalue=3.1120905511061726e-12)\n",
      "MSE:  0.1\n",
      "MAE:  0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.92        28\n",
      "           1       0.95      0.82      0.88        22\n",
      "\n",
      "    accuracy                           0.90        50\n",
      "   macro avg       0.91      0.89      0.90        50\n",
      "weighted avg       0.90      0.90      0.90        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  indivisible\n",
      "SPEARMAN:  SignificanceResult(statistic=0.4745734709147427, pvalue=0.0004977039759165544)\n",
      "MSE:  0.12\n",
      "MAE:  0.12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93        42\n",
      "           1       0.75      0.38      0.50         8\n",
      "\n",
      "    accuracy                           0.88        50\n",
      "   macro avg       0.82      0.68      0.72        50\n",
      "weighted avg       0.87      0.88      0.86        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  peoplecentrism\n",
      "SPEARMAN:  SignificanceResult(statistic=0.5967763691724937, pvalue=4.782741177369476e-06)\n",
      "MSE:  0.2\n",
      "MAE:  0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82        27\n",
      "           1       0.81      0.74      0.77        23\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.80      0.80      0.80        50\n",
      "weighted avg       0.80      0.80      0.80        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  antielitism\n",
      "SPEARMAN:  SignificanceResult(statistic=0.8027395390655511, pvalue=2.3613620747482377e-12)\n",
      "MSE:  0.1\n",
      "MAE:  0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.83      0.88        23\n",
      "           1       0.87      0.96      0.91        27\n",
      "\n",
      "    accuracy                           0.90        50\n",
      "   macro avg       0.91      0.89      0.90        50\n",
      "weighted avg       0.91      0.90      0.90        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  simplicism\n",
      "SPEARMAN:  SignificanceResult(statistic=0.5144957554275266, pvalue=0.0001321924259760062)\n",
      "MSE:  0.2\n",
      "MAE:  0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.86        34\n",
      "           1       0.80      0.50      0.62        16\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.80      0.72      0.74        50\n",
      "weighted avg       0.80      0.80      0.79        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  emotional\n",
      "SPEARMAN:  SignificanceResult(statistic=0.7278401572166632, pvalue=2.1158103674208655e-09)\n",
      "MSE:  0.12\n",
      "MAE:  0.12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.76      0.81        17\n",
      "           1       0.89      0.94      0.91        33\n",
      "\n",
      "    accuracy                           0.88        50\n",
      "   macro avg       0.88      0.85      0.86        50\n",
      "weighted avg       0.88      0.88      0.88        50\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calcola_prestazioni(ground_df, classification_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cccd000",
   "metadata": {},
   "source": [
    "### Zero Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "60fa3972",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('genai/v2/zeroshot_6features_prompt.txt', 'r', encoding=\"utf8\") as f:\n",
    "    zero_shot_prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9628bb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 "
     ]
    }
   ],
   "source": [
    "#zero_shot_classification = pd.read_csv(\"genai/zero-shot_50_texts_classifications.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "zero_shot_classification = calcola_classificazioni(texts_to_classify, zero_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "acdbf688",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_classification.to_csv(\"genai/v2/zeroshot_6features_classifications.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "16d463fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANALISI:  manichean\n",
      "SPEARMAN:  SignificanceResult(statistic=0.5942944359687179, pvalue=5.358675824345657e-06)\n",
      "MSE:  0.2\n",
      "MAE:  0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83        28\n",
      "           1       0.83      0.68      0.75        22\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.81      0.79      0.79        50\n",
      "weighted avg       0.80      0.80      0.80        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  indivisible\n",
      "SPEARMAN:  SignificanceResult(statistic=nan, pvalue=nan)\n",
      "MSE:  0.16\n",
      "MAE:  0.16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91        42\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.42      0.50      0.46        50\n",
      "weighted avg       0.71      0.84      0.77        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  peoplecentrism\n",
      "SPEARMAN:  SignificanceResult(statistic=0.726106525690946, pvalue=2.4107939361602424e-09)\n",
      "MSE:  0.14\n",
      "MAE:  0.14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86        27\n",
      "           1       0.81      0.91      0.86        23\n",
      "\n",
      "    accuracy                           0.86        50\n",
      "   macro avg       0.86      0.86      0.86        50\n",
      "weighted avg       0.87      0.86      0.86        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  antielitism\n",
      "SPEARMAN:  SignificanceResult(statistic=0.7092993656151905, pvalue=8.135044759645468e-09)\n",
      "MSE:  0.16\n",
      "MAE:  0.16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.65      0.79        23\n",
      "           1       0.77      1.00      0.87        27\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.89      0.83      0.83        50\n",
      "weighted avg       0.88      0.84      0.83        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  simplicism\n",
      "SPEARMAN:  SignificanceResult(statistic=0.3131310527099808, pvalue=0.026816449276872226)\n",
      "MSE:  0.34\n",
      "MAE:  0.34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.65      0.72        34\n",
      "           1       0.48      0.69      0.56        16\n",
      "\n",
      "    accuracy                           0.66        50\n",
      "   macro avg       0.65      0.67      0.64        50\n",
      "weighted avg       0.71      0.66      0.67        50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ANALISI:  emotional\n",
      "SPEARMAN:  SignificanceResult(statistic=0.6380199530934721, pvalue=6.229364855434033e-07)\n",
      "MSE:  0.16\n",
      "MAE:  0.16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.59      0.71        17\n",
      "           1       0.82      0.97      0.89        33\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.86      0.78      0.80        50\n",
      "weighted avg       0.85      0.84      0.83        50\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:4916: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "calcola_prestazioni(ground_df, zero_shot_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f9e14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
