{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50e595b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff15d6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94eca168",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#annotated_df = pd.read_csv(\"data/annotated_dataset/annotated_texts_repr.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "annotated_df = pd.read_csv(\"data/annotated_dataset/annotated_texts_repr_pro_complete.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "meta_df = pd.read_csv(\"data/cleaned_dataset/meta.tsv\", sep=\",\", encoding=\"utf-8\")\n",
    "merged_df = annotated_df.merge(meta_df, how='left', left_on='id', right_on=\"ID\")\n",
    "\n",
    "ling_prof_df = merged_df[[\"id\", \"pop_sum\",\"polarization\",\"Speaker_ID\", \"Speaker_party\",\"Party_orientation\",\"linguistic_profile_pro\", \"tfidf_pro\", \"doc_embedding_pro\", \"docembedding_pos_pro\"]]\n",
    "diz = {\n",
    "    \"LN-Aut\": \"Lega\",\n",
    "    \"L-SP\": \"Lega\",\n",
    "    \"M5S.1\": \"M5S\",\n",
    "    \"M5S.2\": \"M5S\",\n",
    "}\n",
    "ling_prof_df = ling_prof_df.replace({\"Speaker_party\": diz})\n",
    "ling_prof_df = ling_prof_df.rename(columns={\"linguistic_profile_pro\": \"linguistic_profile\", \"tfidf_pro\": \"tfidf\", \"doc_embedding_pro\":\"doc_embedding\", \"docembedding_pos_pro\":\"pos_docembedding\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01f3b7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std_lists(lists):\n",
    "    lists = np.array([ast.literal_eval(item) for item in lists])\n",
    "    return np.mean(lists, axis=0).tolist(), np.std(lists, axis=0).tolist()\n",
    "\n",
    "#Aggregazione per senatore\n",
    "df_grouped = ling_prof_df.groupby('Speaker_ID', as_index=False).agg({\n",
    "    'pop_sum': lambda x: x.sum() / x.count(),\n",
    "    'polarization': lambda x: x.sum() / x.count(),\n",
    "    'Speaker_party': lambda x: x.mode()[0],\n",
    "    'Party_orientation': lambda x: x.mode()[0]\n",
    "})\n",
    "\n",
    "#Media e std delle rappresentazioni del testo (per tutti i testi di un senatore)\n",
    "for col in ['linguistic_profile', 'tfidf', 'doc_embedding', 'pos_docembedding']:\n",
    "    df_grouped[col], df_grouped[col + '_std'] = zip(*ling_prof_df.groupby('Speaker_ID')[col].apply(lambda x: mean_std_lists(list(x))))\n",
    "\n",
    "df_grouped[\"linguistic_profile\"] = df_grouped[\"linguistic_profile\"] + df_grouped[\"linguistic_profile_std\"]\n",
    "df_grouped[\"tfidf\"] = df_grouped[\"tfidf\"] + df_grouped[\"tfidf_std\"]\n",
    "df_grouped[\"doc_embedding\"] = df_grouped[\"doc_embedding\"] + df_grouped[\"doc_embedding_std\"]\n",
    "df_grouped[\"pos_docembedding\"] = df_grouped[\"pos_docembedding\"] + df_grouped[\"pos_docembedding_std\"]\n",
    "    \n",
    "group_sizes = ling_prof_df.groupby('Speaker_ID').size().reset_index(name='Count_Per_Group') #quanti testi per senatore\n",
    "df_grouped = df_grouped.merge(group_sizes, on='Speaker_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31cd9a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_grouped.to_csv(\"data/annotated_dataset/speaker_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a2d067",
   "metadata": {},
   "source": [
    "#### Estraggo X e y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "723400ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_df = pd.read_csv(\"data/annotated_dataset/speaker_data.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "speaker_df = speaker_df[speaker_df[\"Count_Per_Group\"] > 10]\n",
    "\n",
    "x_tfidf = speaker_df[\"tfidf\"]\n",
    "x_tfidf = np.array([ast.literal_eval(item) for item in x_tfidf])\n",
    "\n",
    "x_docembedding = speaker_df[\"doc_embedding\"]\n",
    "x_docembedding = np.array([ast.literal_eval(item) for item in x_docembedding])\n",
    "\n",
    "x_pos_docembedding = speaker_df[\"pos_docembedding\"]\n",
    "x_pos_docembedding = np.array([ast.literal_eval(item) for item in x_pos_docembedding])\n",
    "\n",
    "x_linguistic_profile = speaker_df[\"linguistic_profile\"]\n",
    "x_linguistic_profile = np.array([ast.literal_eval(item) for item in x_linguistic_profile])\n",
    "\n",
    "reprs = {\n",
    "    \"tfidf\": x_tfidf,\n",
    "    \"doc_embedding\": x_docembedding,\n",
    "    \"pos_docembedding\": x_pos_docembedding,\n",
    "    \"linguistic_profile\": x_linguistic_profile\n",
    "}\n",
    "\n",
    "y_pol = speaker_df[\"polarization\"]\n",
    "y_pop = speaker_df[\"pop_sum\"]\n",
    "y_pop_bin = [0 if x < 2 else 1 for x in y_pop]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1fd79b",
   "metadata": {},
   "source": [
    "## Regressione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc6fe3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "scaler = StandardScaler()\n",
    "def regressione(reprs, y):\n",
    "    for name, X in reprs.items():\n",
    "        print(name)\n",
    "        X = scaler.fit_transform(X)\n",
    "        cv_scores = cross_val_score(model, X, y, cv=3, scoring='r2')  # R^2 Score\n",
    "        cv_predictions = cross_val_predict(model, X, y, cv=3)\n",
    "\n",
    "        print(\"Cross-Validation R² Scores:\", cv_scores)\n",
    "        print(\"Mean R² Score:\", cv_scores.mean())\n",
    "\n",
    "        mse = mean_squared_error(y, cv_predictions)\n",
    "        spearman = stats.spearmanr(y, cv_predictions)\n",
    "        \n",
    "        print(\"Cross-Validated MSE:\", mse)\n",
    "        print(\"Spearman:\", spearman)\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58b0c857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf\n",
      "Cross-Validation R² Scores: [0.62570368 0.67371458 0.68717556]\n",
      "Mean R² Score: 0.6621979389447488\n",
      "Cross-Validated MSE: 0.34233359363247823\n",
      "Spearman: SignificanceResult(statistic=0.8209921611229694, pvalue=3.5604708173779363e-78)\n",
      "\n",
      "\n",
      "\n",
      "doc_embedding\n",
      "Cross-Validation R² Scores: [0.4301833  0.32932184 0.34026724]\n",
      "Mean R² Score: 0.36659079339117606\n",
      "Cross-Validated MSE: 0.6329532439782148\n",
      "Spearman: SignificanceResult(statistic=0.7337698103620822, pvalue=1.7458807620159238e-54)\n",
      "\n",
      "\n",
      "\n",
      "pos_docembedding\n",
      "Cross-Validation R² Scores: [0.48500917 0.51050037 0.52041807]\n",
      "Mean R² Score: 0.5053092012836897\n",
      "Cross-Validated MSE: 0.4990100067901557\n",
      "Spearman: SignificanceResult(statistic=0.7822060670673977, pvalue=2.746046061975103e-66)\n",
      "\n",
      "\n",
      "\n",
      "linguistic_profile\n",
      "Cross-Validation R² Scores: [ 0.26515859 -0.06502144  0.23664814]\n",
      "Mean R² Score: 0.14559509388114503\n",
      "Cross-Validated MSE: 0.854745290599053\n",
      "Spearman: SignificanceResult(statistic=0.6610316302018271, pvalue=6.178635069701292e-41)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regressione(reprs, y_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7db41559",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf\n",
      "Cross-Validation R² Scores: [0.53534629 0.58055947 0.51870942]\n",
      "Mean R² Score: 0.5448717249046443\n",
      "Cross-Validated MSE: 0.1402155241324299\n",
      "Spearman: SignificanceResult(statistic=0.744919472296562, pvalue=5.800422382480333e-57)\n",
      "\n",
      "\n",
      "\n",
      "doc_embedding\n",
      "Cross-Validation R² Scores: [-0.69699673 -0.39784321 -0.11240653]\n",
      "Mean R² Score: -0.4024154894505367\n",
      "Cross-Validated MSE: 0.4297830361562644\n",
      "Spearman: SignificanceResult(statistic=0.5350730691486638, pvalue=9.92976330952728e-25)\n",
      "\n",
      "\n",
      "\n",
      "pos_docembedding\n",
      "Cross-Validation R² Scores: [-0.60327721 -1.46174049 -0.26754508]\n",
      "Mean R² Score: -0.7775209253426114\n",
      "Cross-Validated MSE: 0.5429915473486618\n",
      "Spearman: SignificanceResult(statistic=0.489165471654992, pvalue=2.352436814187315e-20)\n",
      "\n",
      "\n",
      "\n",
      "linguistic_profile\n",
      "Cross-Validation R² Scores: [-0.6449824  -0.59766782 -0.4888334 ]\n",
      "Mean R² Score: -0.5771612073666954\n",
      "Cross-Validated MSE: 0.48466788399847904\n",
      "Spearman: SignificanceResult(statistic=0.4166460627934451, pvalue=1.1708507128118755e-14)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regressione(reprs, y_pol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cd011b",
   "metadata": {},
   "source": [
    "# Classificazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a45e5641",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pol_discr = [0 if x <= 0.75 else 1 if x<=1.45 else 2 for x in y_pol]\n",
    "y_pop_discr = [0 if x <= 1 else 1 for x in y_pop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c29523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc = LinearSVC(C=0.1, random_state=42)\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=150, \n",
    "                             criterion='gini', \n",
    "                             max_depth=None, \n",
    "                             min_samples_split=2, \n",
    "                             min_samples_leaf=1, \n",
    "                             min_weight_fraction_leaf=0.0, \n",
    "                             max_features='sqrt', \n",
    "                             random_state=0, \n",
    "                             n_jobs=-1)\n",
    "\n",
    "clf_lgbm = LGBMClassifier(random_state=8, verbose=-1)\n",
    "\n",
    "models = {\n",
    "    \"svc\": clf_svc,\n",
    "    \"rf\": clf_rf,\n",
    "    \"lgbm\": clf_lgbm\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bc094ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_x_repr(reprs, y):\n",
    "    for model_name, model in models.items():\n",
    "        print(\"-------------------\")\n",
    "        for rep_name, rep in reprs.items():\n",
    "            print(model_name)\n",
    "            print(rep_name)\n",
    "            predictions = cross_val_predict(model, rep, y, cv=5)\n",
    "            print(classification_report(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f3227e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "svc\n",
      "tfidf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.78       144\n",
      "           1       0.80      0.86      0.83       171\n",
      "\n",
      "    accuracy                           0.81       315\n",
      "   macro avg       0.81      0.80      0.81       315\n",
      "weighted avg       0.81      0.81      0.81       315\n",
      "\n",
      "svc\n",
      "doc_embedding\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.79       144\n",
      "           1       0.80      0.87      0.83       171\n",
      "\n",
      "    accuracy                           0.81       315\n",
      "   macro avg       0.81      0.81      0.81       315\n",
      "weighted avg       0.81      0.81      0.81       315\n",
      "\n",
      "svc\n",
      "pos_docembedding\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.79       144\n",
      "           1       0.80      0.87      0.83       171\n",
      "\n",
      "    accuracy                           0.81       315\n",
      "   macro avg       0.81      0.81      0.81       315\n",
      "weighted avg       0.81      0.81      0.81       315\n",
      "\n",
      "svc\n",
      "linguistic_profile\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.62      0.62       144\n",
      "           1       0.68      0.67      0.67       171\n",
      "\n",
      "    accuracy                           0.65       315\n",
      "   macro avg       0.65      0.65      0.65       315\n",
      "weighted avg       0.65      0.65      0.65       315\n",
      "\n",
      "-------------------\n",
      "rf\n",
      "tfidf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79       144\n",
      "           1       0.81      0.86      0.83       171\n",
      "\n",
      "    accuracy                           0.81       315\n",
      "   macro avg       0.81      0.81      0.81       315\n",
      "weighted avg       0.81      0.81      0.81       315\n",
      "\n",
      "rf\n",
      "doc_embedding\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80       144\n",
      "           1       0.83      0.84      0.83       171\n",
      "\n",
      "    accuracy                           0.82       315\n",
      "   macro avg       0.82      0.82      0.82       315\n",
      "weighted avg       0.82      0.82      0.82       315\n",
      "\n",
      "rf\n",
      "pos_docembedding\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81       144\n",
      "           1       0.84      0.82      0.83       171\n",
      "\n",
      "    accuracy                           0.82       315\n",
      "   macro avg       0.82      0.82      0.82       315\n",
      "weighted avg       0.82      0.82      0.82       315\n",
      "\n",
      "rf\n",
      "linguistic_profile\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77       144\n",
      "           1       0.81      0.80      0.81       171\n",
      "\n",
      "    accuracy                           0.79       315\n",
      "   macro avg       0.79      0.79      0.79       315\n",
      "weighted avg       0.79      0.79      0.79       315\n",
      "\n",
      "-------------------\n",
      "lgbm\n",
      "tfidf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.81       144\n",
      "           1       0.83      0.87      0.85       171\n",
      "\n",
      "    accuracy                           0.83       315\n",
      "   macro avg       0.83      0.83      0.83       315\n",
      "weighted avg       0.83      0.83      0.83       315\n",
      "\n",
      "lgbm\n",
      "doc_embedding\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82       144\n",
      "           1       0.85      0.84      0.84       171\n",
      "\n",
      "    accuracy                           0.83       315\n",
      "   macro avg       0.83      0.83      0.83       315\n",
      "weighted avg       0.83      0.83      0.83       315\n",
      "\n",
      "lgbm\n",
      "pos_docembedding\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79       144\n",
      "           1       0.81      0.86      0.84       171\n",
      "\n",
      "    accuracy                           0.82       315\n",
      "   macro avg       0.82      0.81      0.81       315\n",
      "weighted avg       0.82      0.82      0.82       315\n",
      "\n",
      "lgbm\n",
      "linguistic_profile\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79       144\n",
      "           1       0.83      0.81      0.82       171\n",
      "\n",
      "    accuracy                           0.81       315\n",
      "   macro avg       0.80      0.81      0.81       315\n",
      "weighted avg       0.81      0.81      0.81       315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_x_repr(reprs, y_pop_discr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c03b13da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "svc\n",
      "tfidf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.60      0.62        89\n",
      "           1       0.63      0.53      0.58       116\n",
      "           2       0.63      0.76      0.69       110\n",
      "\n",
      "    accuracy                           0.63       315\n",
      "   macro avg       0.63      0.63      0.63       315\n",
      "weighted avg       0.63      0.63      0.63       315\n",
      "\n",
      "svc\n",
      "doc_embedding\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.58      0.60        89\n",
      "           1       0.62      0.52      0.56       116\n",
      "           2       0.62      0.76      0.69       110\n",
      "\n",
      "    accuracy                           0.62       315\n",
      "   macro avg       0.62      0.62      0.62       315\n",
      "weighted avg       0.62      0.62      0.62       315\n",
      "\n",
      "svc\n",
      "pos_docembedding\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.57      0.60        89\n",
      "           1       0.61      0.52      0.56       116\n",
      "           2       0.62      0.76      0.69       110\n",
      "\n",
      "    accuracy                           0.62       315\n",
      "   macro avg       0.62      0.62      0.61       315\n",
      "weighted avg       0.62      0.62      0.61       315\n",
      "\n",
      "svc\n",
      "linguistic_profile\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.63      0.47        89\n",
      "           1       0.43      0.43      0.43       116\n",
      "           2       0.63      0.28      0.39       110\n",
      "\n",
      "    accuracy                           0.43       315\n",
      "   macro avg       0.48      0.45      0.43       315\n",
      "weighted avg       0.49      0.43      0.43       315\n",
      "\n",
      "-------------------\n",
      "rf\n",
      "tfidf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.44      0.55        89\n",
      "           1       0.59      0.70      0.64       116\n",
      "           2       0.70      0.79      0.74       110\n",
      "\n",
      "    accuracy                           0.66       315\n",
      "   macro avg       0.67      0.64      0.64       315\n",
      "weighted avg       0.67      0.66      0.65       315\n",
      "\n",
      "rf\n",
      "doc_embedding\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.52      0.54        89\n",
      "           1       0.60      0.64      0.62       116\n",
      "           2       0.68      0.69      0.69       110\n",
      "\n",
      "    accuracy                           0.62       315\n",
      "   macro avg       0.62      0.62      0.62       315\n",
      "weighted avg       0.62      0.62      0.62       315\n",
      "\n",
      "rf\n",
      "pos_docembedding\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.54      0.57        89\n",
      "           1       0.59      0.64      0.61       116\n",
      "           2       0.68      0.67      0.68       110\n",
      "\n",
      "    accuracy                           0.62       315\n",
      "   macro avg       0.62      0.62      0.62       315\n",
      "weighted avg       0.62      0.62      0.62       315\n",
      "\n",
      "rf\n",
      "linguistic_profile\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.42      0.50        89\n",
      "           1       0.56      0.66      0.61       116\n",
      "           2       0.64      0.70      0.67       110\n",
      "\n",
      "    accuracy                           0.60       315\n",
      "   macro avg       0.61      0.59      0.59       315\n",
      "weighted avg       0.61      0.60      0.60       315\n",
      "\n",
      "-------------------\n",
      "lgbm\n",
      "tfidf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.63      0.67        89\n",
      "           1       0.67      0.72      0.69       116\n",
      "           2       0.81      0.83      0.82       110\n",
      "\n",
      "    accuracy                           0.73       315\n",
      "   macro avg       0.74      0.73      0.73       315\n",
      "weighted avg       0.73      0.73      0.73       315\n",
      "\n",
      "lgbm\n",
      "doc_embedding\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.58      0.60        89\n",
      "           1       0.58      0.59      0.59       116\n",
      "           2       0.69      0.70      0.70       110\n",
      "\n",
      "    accuracy                           0.63       315\n",
      "   macro avg       0.63      0.63      0.63       315\n",
      "weighted avg       0.63      0.63      0.63       315\n",
      "\n",
      "lgbm\n",
      "pos_docembedding\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61        89\n",
      "           1       0.59      0.56      0.57       116\n",
      "           2       0.70      0.74      0.72       110\n",
      "\n",
      "    accuracy                           0.63       315\n",
      "   macro avg       0.63      0.63      0.63       315\n",
      "weighted avg       0.63      0.63      0.63       315\n",
      "\n",
      "lgbm\n",
      "linguistic_profile\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.48      0.52        89\n",
      "           1       0.56      0.56      0.56       116\n",
      "           2       0.68      0.76      0.72       110\n",
      "\n",
      "    accuracy                           0.61       315\n",
      "   macro avg       0.60      0.60      0.60       315\n",
      "weighted avg       0.60      0.61      0.61       315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_x_repr(reprs, y_pol_discr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ae9545",
   "metadata": {},
   "source": [
    "### Classificazione top, con ottimizzazione parametri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a14d0ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "def linearSvcBestParams(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    svc = LinearSVC(dual=False, max_iter=10000)\n",
    "\n",
    "    param_grid = {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'loss': ['squared_hinge', 'hinge'],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'class_weight': ['balanced']\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(svc, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "    print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    best_model = LinearSVC(dual=False, **best_params)\n",
    "    \n",
    "    X_scaled = scaler.transform(X)\n",
    "    predictions = cross_val_predict(best_model, X_scaled, y, cv=3)\n",
    "    \n",
    "    print(classification_report(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71361ed3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Parameters: {'C': 0.1, 'class_weight': 'balanced', 'loss': 'squared_hinge', 'penalty': 'l1'}\n",
      "Best Cross-Validation Accuracy: 0.7541176470588236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67        89\n",
      "           1       0.71      0.72      0.71       116\n",
      "           2       0.83      0.81      0.82       110\n",
      "\n",
      "    accuracy                           0.74       315\n",
      "   macro avg       0.74      0.74      0.74       315\n",
      "weighted avg       0.74      0.74      0.74       315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linearSvcBestParams(x_tfidf, y_pol_discr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd2ae0d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Parameters: {'C': 0.1, 'class_weight': 'balanced', 'loss': 'squared_hinge', 'penalty': 'l1'}\n",
      "Best Cross-Validation Accuracy: 0.8569411764705883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82       144\n",
      "           1       0.87      0.82      0.84       171\n",
      "\n",
      "    accuracy                           0.83       315\n",
      "   macro avg       0.83      0.84      0.83       315\n",
      "weighted avg       0.84      0.83      0.84       315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linearSvcBestParams(x_tfidf, y_pop_discr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb89aee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
